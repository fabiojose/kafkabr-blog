---
title: Como implementar Dead-letter Topic com Spring Kafka 
author: fabiojose
date:   2020-05-18 22:03:36 -0300
categories: [Artigos, Arquitetura]
tags: [t√≥pico, spring, spring-kafka, dlt, java]
toc: true
---

_Dead-letter Topic_, [_Dead-letter Queue_](https://en.m.wikipedia.org/wiki/Dead_letter_queue) ou em bom e velho portugu√™s: __T√≥picos de mensagens n√£o-entregues__. S√£o t√≥picos necess√°rios em sistemas distribu√≠dos onde a comunica√ß√£o √© ass√≠ncrona e atrav√©s de brokers como o Kafka.

Os dados que chegam nestes t√≥picos passaram por todas as tentativas poss√≠veis para tratamento de erros e j√° n√£o resta mais nada a ser feito, se n√£o, a interven√ß√£o humana. Assim, __n√£o ser√° qualquer erro__ que levar√° mensagens ou eventos a serem publicados em um t√≥pico _dead-letter_.

> No mundo Kafka um t√≥pico dead-letter √© destinado aos registros consumidos, que por algum erro irrecuper√°vel n√£o puderam ser processados com sucesso.

---

Neste artigo ser√° demonstrada uma abordagem para implementar DLT no Kafka, utilizando Java e Spring. Para os impacientes üßê, estes s√£o os fontes :

- [C√≥digo fonte no GitHub](https://github/fabiojose/spring-kafka-dlt-ex)

---

### Classificar Erros

Antes de escrever qualquer linha de c√≥digo √© necess√°rio classificar os erros e como ser√£o tratados.

Existem dois tipos de erros: 

- recuper√°veis
- n√£o-recuper√°veis

Os erros __recuper√°veis__ ou que podem ser tratados, s√£o aqueles onde  alguma abordagem ser√° empregada para tentar finalizar o fluxo com sucesso.

Por exemplo, no Java, os erros [`ConnectException`](https://docs.oracle.com/javase/8/docs/api/java/net/ConnectException.html) e [`UnknownHostException`](https://docs.oracle.com/javase/8/docs/api/java/net/UnknownHostException.html) podem ser recuperados atrav√©s de retentativas, pois normalmente s√£o causados por instabilidades moment√¢neas no servi√ßo ou na rede.

J√° os __n√£o-recuper√°veis__ s√£o aqueles que independente do que seja feito, n√£o ser√° poss√≠vel finalizar o fluxo com sucesso. Logo, estes s√£o candidatos a seguirem diretamente para o t√≥pico dead-letter. E como exemplo, se voc√™ utiliza Avro, o erro [`AvroMissingFieldException`](http://avro.apache.org/docs/1.9.2/api/java/index.html) indica a aus√™ncia de um campo requerido, n√£o havendo nada a fazer. Portanto ser√° in√∫til a retentativa, por exemplo.

---

__E al√©m dos erros t√©cnicos, voc√™ tamb√©m dever√° classificar seus erros de neg√≥cio e escolher uma estrat√©gia para trat√°-los.__

---

Bem, agora veremos como implementar DLT para problemas t√©cnicos no Java. E √© bem prov√°vel que voc√™ encontre equivalentes na sua linguagem ou framework.

### Recuper√°veis

Aqui segue uma lista de erros t√©cnicos recuper√°veis que, em nome da simplicidade, ser√£o tratados atrav√©s de retentativas.

- [`ConnectException`](https://docs.oracle.com/javase/8/docs/api/java/net/ConnectException.html)
- [`UnknownHostException`](https://docs.oracle.com/javase/8/docs/api/java/net/UnknownHostException.html)
- `ProductNotFoundException`: a t√≠tulo de exemplo, este erro de neg√≥cio foi definido como trat√°vel. Porque um servi√ßo chamado _Catalogo_, que faz [event-sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) das mudan√ßas emitidas pelo servi√ßo _Produto_, ainda n√£o processou o evento com o produto em quest√£o. Mas atrav√©s da retentativa seu fluxo poder√° finalizar com sucesso.

### N√£o-recuper√°veis

Estes s√£o alguns dos erros n√£o-recuper√°veis, ou seja, se passarem pelo mesmo processo de retentativas somente consumiriam recursos, sem chances de finalizar com sucesso.

- [`AvroMissingFieldException`](http://avro.apache.org/docs/1.9.2/api/java/index.html)
- [`NullPointerException`](https://docs.oracle.com/javase/8/docs/api/java/lang/NullPointerException.html)
- [`ClassCastException`](https://docs.oracle.com/javase/8/docs/api/java/lang/ClassCastException.html)
- [`RecordTooLargeException`](https://kafka.apache.org/20/javadoc/index.html?org/apache/kafka/common/errors/RecordTooLargeException.html)
- `StockNotAvailableException`: como exemplo, este erro de neg√≥cio foi classificado como irrecuper√°vel. Porque a falta de produtos no estoque n√£o ser√° resolvida com retentativas, por exemplo.

### Implementa√ß√£o

> Existe um [√≥timo artigo](https://eng.uber.com/reliable-reprocessing/) no blog de engenharia do Uber que descreve uma arquitetura para dead-letter. Vale a leitura!

Esta implementa√ß√£o foi dividida em tr√™s partes:

- t√≥picos
- constru√ß√£o
- tratamento

#### T√≥picos

Para cada processo que ter√° tratamento _dead-letter_, ser√° criado um t√≥pico com o sufixo `-dlt`. Tome como exemplo um processo que realiza a reserva de estoque a partir das ordens de compra publicadas no t√≥pico `ordem-compra`. Ent√£o, ao inv√©s de criar um t√≥pico ordem-compra-dlq, ser√° utilizado um nome relevante ao processo que est√° falhando:

- `reservar-estoque-dlt`

E mais os t√≥picos para retentativas, que devem ser quantos forem necess√°rios at√© finalmente o registro chegar ao t√≥pico _dead-letter_. Digamos que ser√£o no m√°ximo quatro retentativas al√©m da inicial:

- `reservar-estoque-retry-1`
- `reservar-estoque-retry-2`
- `reservar-estoque-retry-3`
- `reservar-estoque-retry-4`

Os t√≥picos devem ter caracter√≠sticas que n√£o interfiram no andamento das retentativas ou na publica√ß√£o do t√≥pico dead-letter. Um exemplo √© a configura√ß√£o `max.message.bytes`, que pode acarretar um erro chamado `message too large`. Portanto os t√≥picos dever√£o permitir mensagens maiores, caso contr√°rio tamb√©m n√£o ser√° poss√≠vel utiliz√°-los porque s√£o id√™nticos ao principal, inclusive com as mesmas limita√ß√µes.

#### Constru√ß√£o

A constru√ß√£o foi feita com Spring Kafka porque ele j√° vem com muitas utilidades para tratamento para _dead-letter_, o que contribui muito com a produtividade se ela √© o foco no seu projeto. Mas nada impede que voc√™ escreva a mesma solu√ß√£o com Clientes Kafka no Java ou na sua linguagem do seu projeto.

Para utilizar os recursos destinados a dead-letter, √© necess√°rio customizar a f√°brica de objetos encarregada de produzir _listeners_ Kafka no Spring.

Assim, a configura√ß√£o program√°tica foi sub-dividida em tr√™s partes:

- `resolver`: respons√°vel por determinar o t√≥pico destino do registro que est√° no contexto do erro.
- `errorHandler`: manipulador do erro
- `kafkaListernerContainerFactory`: fabrica inst√¢ncias que s√£o utilizadas nos m√©todos anotados com `@KafkaListener`

E para cada uma das sub-divis√µes existe uma implementa√ß√£o __Main__ e outra __Retry__. Como √© poss√≠vel imaginar, uma cuida das configura√ß√µes para o processamento principal outro para as retentativas.

__Main resolver__, respons√°vel por determinar qual o t√≥pico destino com base no erro-raiz lan√ßado ao processar o registro consumido do t√≥pico `ordem-compra`:

```java
@Bean
public BiFunction < ConsumerRecord < ? , ? > , Exception, TopicPartition >
 mainResolver() {

  return new BiFunction < ConsumerRecord < ? , ? > , Exception, TopicPartition > () {
   @Override
   public TopicPartition apply(ConsumerRecord < ? , ? > r, Exception e) {

    // ####
    // Por padr√£o, quando √© n√£o-recuper√°vel, segue diretamente p/ dead-letter
    TopicPartition result =
     new TopicPartition(dltTopic,
      QUALQUER_PARTICAO);

    // ####
    // Trata-se de um erro recuper√°vel?
    final boolean recuperavel = isRecuperavel(e);
    if (recuperavel) {

     Optional < String > origem =
      topicoOrigem(r.headers())
      .or(() -> Optional.of(NENHUM_CABECALHO));

     // ####
     // Se origem for outro t√≥pico, segue para o primeiro retry
     String destino =
      origem
      .filter(topico -> !topico.matches(retryTopicsPattern))
      .map(t -> retryFirstTopic)
      .orElse(dltTopic);

     result = new TopicPartition(destino, QUALQUER_PARTICAO);
    }

    return result;
   }
  };
 }
```

__Main error handler__, que utiliza o __Main resolver__ e √© respons√°vel por definir duas configura√ß√µes essenciais para tratamento dos erros:

- [`DeadLetterPublishingRecoverer`](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/DeadLetterPublishingRecoverer.html): inicia o fluxo DLT, que √© delegado pelo SeekToCurrentErrorHandler caso as retentativas locais n√£o resolvam o erro.
- [`SeekToCurrentErrorHandler`](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/SeekToCurrentErrorHandler.html): manipula qualquer erro que seja lan√ßado no m√©todo anotado com `@KafkaListener`. Naturalmente, se voc√™ captur√°-los com `catch` e n√£o permitir que eles _subam na pilha_, n√£o ser√° poss√≠vel trat√°-los.

```java
@Bean
public SeekToCurrentErrorHandler mainErrorHandler(
 @Qualifier("mainResolver")
 BiFunction < ConsumerRecord < ? , ? > , Exception, TopicPartition > resolver,
 KafkaTemplate < ? , ? > template) {

 // ####
 // Recupera√ß√£o usando dead-letter 
 DeadLetterPublishingRecoverer recoverer =
  new DeadLetterPublishingRecoverer(template, resolver);

 // ####
 // Tentar 3x localmente antes de iniciar o fluxo dead-letter
 SeekToCurrentErrorHandler handler =
  new SeekToCurrentErrorHandler(recoverer, RETENTAR_3X);

 // ####
 // Lista das exce√ß√µes n√£o-recuper√°veis, para evitar o retry local
 excecoes.getNaoRecuperavies().forEach(e ->
  handler.addNotRetryableException(e));

 return handler;
}
```

__Main listener factory__, encarregado de fabricar os consumidores que processam registros do t√≥p√≠co `ordem-compra`.

```java
@Bean
public KafkaListenerContainerFactory < ConcurrentMessageListenerContainer < String, GenericRecord >>
 mainKafkaListenerContainerFactory(
  @Qualifier("mainErrorHandler") SeekToCurrentErrorHandler errorHandler,
  KafkaProperties properties,
  ConsumerFactory < String, GenericRecord > factory) {

  ConcurrentKafkaListenerContainerFactory < String, GenericRecord > listener =
   new ConcurrentKafkaListenerContainerFactory < > ();

  listener.setConsumerFactory(factory);

  // ####
  // Utilizando o mainErrorHandler para tratar os erros
  listener.setErrorHandler(errorHandler);

  // Falhar, caso os t√≥picos n√£o existam?
  listener.getContainerProperties()
   .setMissingTopicsFatal(missingTopicsFatal);

  // Commit do offset no registro, logo ap√≥s process√°-lo no listener
  listener.getContainerProperties().setAckMode(AckMode.MANUAL);

  // Commits s√≠ncronos
  listener.getContainerProperties().setSyncCommits(Boolean.TRUE);

  return listener;
 }
```

Ent√£o, basta anotar o m√©todo como segue.

Mas vale ressaltar que o offset sempre dever√° ser confirmado, porque todo o fluxo que trata os erros ser√° feito por retentativa e talvez culminando no t√≥pico dead-letter. _Analise o seu caso-de-uso e entenda se esta abordagem tamb√©m se aplicada._

```java
@KafkaListener(
 id = "main-kafka-listener",
 topics = "${app.kafka.consumer.topics}",
 containerFactory = "mainKafkaListenerContainerFactory"
)
public void consume(@Payload ConsumerRecord < String, GenericRecord > record,
 Acknowledgment ack) throws Exception {

 try {

  // #### 
  // Processar
  process(record);

 } finally {

  // ####
  // Sempre confirmar o offset
  ack.acknowledge();
 }

}
```

J√° a configura√ß√£o para o processamento das retentativas segue moldes similares, com algumas exce√ß√µes:

- `resolver`: retorna qual o pr√≥ximo t√≥pico na sequ√™ncia de retentativas ou se √© o `reservar-estoque-dlt`, caso j√° tenham passadas por todas.
- `errorHandler`: nenhuma retentiva local.

Este √© o m√©todo anotado com `@KafkaListener` que tratar√° os t√≥picos `reservar-estoque-retry`:

```java
@KafkaListener(
 id = "retry-kafka-listener",
 topicPattern = "${app.kafka.dlt.retry.topics.pattern}",
 containerFactory = "retryKafkaListenerContainerFactory",
 properties = {
  "fetch.min.bytes=${app.kafka.dlt.retry.min.bytes}",
  "fetch.max.wait.ms=${app.kafka.dlt.retry.max.wait.ms}"
 }
)
public void retry(@Payload ConsumerRecord < String, GenericRecord > record,
 Acknowledgment ack) throws Exception {

 try {

  // ####
  // Reprocessar
  process(record);

 } finally {
  // ####
  // Sempre confirmar o offset
  ack.acknowledge();
 }

}
```

- `topicPattern`: consumir todos os t√≥picos `reservar-estoque-retry`
- `fetch.min.bytes` e `fetch.max.wait.ms`: utilizados para provocar um certo atraso no consumo dos registros, visto que sem eles o consumo seria praticamente instant√¢neo.

Por fim, o `application.properties` ser√° assim: 

```properties
app.kafka.dlt.retry.topics=4
app.kafka.dlt.retry.topics.pattern=reservar-estoque-retry-[0-9]+
app.kafka.dlt.retry.topic.first=reservar-estoque-retry-1
app.kafka.dlt.topic=reservar-estoque-dlt

# Lista de exce√ß√µes recuper√°veis
app.kafka.dlt.excecoes.recuperaveis[0]=java.net.ConnectException
app.kafka.dlt.excecoes.recuperaveis[1]=java.net.UnknownHostException

# Lista de exce√ß√µes n√£o-recuper√°veis
app.kafka.dlt.excecoes.naoRecuperaveis[0]=org.apache.avro.AvroMissingFieldException
app.kafka.dlt.excecoes.naoRecuperaveis[1]=java.lang.NullPointerException

# Provocar atraso no processmento de retentativa
app.kafka.dlt.retry.max.wait.ms=20000
app.kafka.dlt.retry.min.bytes=52428800
```

Todo a implementa√ß√£o est√° dispon√≠vel no Github, _clone it and have fun!_

- [C√≥digo fonte no GitHub](https://github/fabiojose/spring-kafka-dlt-ex)

---

Quando o registro atinge o √∫ltimo t√≥pico de retentativa, que neste caso √© o `reservar-estoque-4` e n√£o seja processado com sucesso, finalmente ele ser√° publicado no t√≥pico _dead-letter_, ent√£o a equipe dever√° estar preparada para o tratamento adequado.

#### Tratamento

Bem, neste momento o registro com problemas j√° desembarcou no t√≥pico `reservar-estoque-dlt` e bem antes disso acontecer um sistema preciso de monitoramento dos t√≥picos deveria ter alertado sobre o uso dos t√≥picos para retentativas, principalmente se os registros est√£o atingindo o `reservar-estoque-retry-4`.

> Veja [neste artigo](https://medium.com/@alvarobacelar/monitorando-um-cluster-kafka-com-ferramentas-open-source-a4032836dc79) como monitorar seu cluster Kafka.

A maneira mais prudente de tratamento, al√©m do monitoramento e um √≥timo sistema de rastreamento distribu√≠do, ser√° construir um processo em que para cada registro publicado no DLT, tickets e notifica√ß√µes ChatOps deveram ser enviados para a equipe respons√°vel.

> Tamb√©m s√£o necess√°rias ferramentas adequadas para, por exemplo, editar registros e coloc√°-los novamente no t√≥pico original.

---

Bem, √© isso! At√© o pr√≥ximo.

